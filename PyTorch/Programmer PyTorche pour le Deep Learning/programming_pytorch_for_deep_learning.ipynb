{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "venv_mappytorch",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Les réseaux de neurones convolutifs ont été utilisés pour reconnaître les chiffres des chèques à la fin des années 90. Il y a eu une base solide pendant tout ce temps, alors pourquoi a-t-on l'impression qu'une explosion s'est produite au cours des dix dernières années ?\n",
    "\n",
    "Les raisons sont nombreuses, mais la principale d'entre elles est l'augmentation des performances des GPU et leur prix de plus en plus abordable. Conçus à l'origine pour les jeux, les GPU doivent effectuer des millions d'opérations matricielles par seconde afin de restituer tous les polygones du jeu de conduite ou de tir auquel vous jouez sur votre console ou votre PC, opérations pour lesquelles un CPU standard n'est tout simplement pas optimisé.\n",
    "\n",
    "Un article publié en 2009~[[1]](#1) soulignait que la formation des réseaux de neurones reposait également sur l'exécution d'un grand nombre d'opérations matricielles. Ces cartes graphiques supplémentaires pourraient donc être utilisées pour accélérer la formation et rendre possible, pour la première fois des architectures de réseaux neuronaux plus grandes et plus profondes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Démarrer avec PyTorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "!nvidia-smi"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Jul  1 19:39:37 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:2D:00.0  On |                  N/A |\n",
      "|  0%   43C    P5    39W / 215W |   1065MiB /  7981MiB |     35%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1644      G   /usr/lib/xorg/Xorg                102MiB |\n",
      "|    0   N/A  N/A      2598      G   /usr/lib/xorg/Xorg                413MiB |\n",
      "|    0   N/A  N/A      2758      G   /usr/bin/gnome-shell               82MiB |\n",
      "|    0   N/A  N/A      3407      G   ...AAAAAAAAA= --shared-files       22MiB |\n",
      "|    0   N/A  N/A      3853      G   /usr/lib/firefox/firefox          161MiB |\n",
      "|    0   N/A  N/A      3936      G   ...gAAAAAAAAA --shared-files      159MiB |\n",
      "|    0   N/A  N/A      4163      G   ...AAAAAAAAA= --shared-files       19MiB |\n",
      "|    0   N/A  N/A     29850      G   ...AAAAAAAAA= --shared-files       66MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "source": [
    "CUDA Version 11.3, on peut donc procéder à l'installation de PyTorch via les instructions trouvable sur leur [site web](https://pytorch.org/)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (2041.3 MB)\n",
      "Collecting torchvision==0.10.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp38-cp38-linux_x86_64.whl (23.2 MB)\n",
      "Collecting torchaudio==0.9.0\n",
      "  Using cached torchaudio-0.9.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: typing-extensions in /home/madjakul/.local/lib/python3.8/site-packages (from torch==1.9.0+cu111) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision==0.10.0+cu111) (7.0.0)\n",
      "Requirement already satisfied: numpy in /home/madjakul/.local/lib/python3.8/site-packages (from torchvision==0.10.0+cu111) (1.19.5)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.1\n",
      "    Uninstalling torch-1.8.1:\n",
      "      Successfully uninstalled torch-1.8.1\n",
      "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "source": [
    "On s'assure ici que CUDA est accesible et crée un tenseur à valeurs aléatoires de taille 2*2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\ntensor([[0.0013, 0.9979],\n        [0.3422, 0.2302]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.rand(2, 2))"
   ]
  },
  {
   "source": [
    "## Tenseurs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Un tenseur est à la fois un conteneur pour les nombres et un ensemble de tuples qui définissent les transformations entre les tenseurs qui produisent de nouveaux tenseurs.\n",
    "\n",
    "Chaque tenseur a un rang qui correspond à son espace dimensionnel. Un simple scalaire—par exemple, 1—peut être représenté comme un tenseur de rang 0, un vecteur est de rang 1, une matrice $n*n$ est de rang 2, et ainsi de suite. Dans l'exemple précédent, nous avons créé un tenseur de rang 2 avec des valeurs aléatoires en utilisant `torch.rand()`. Nous pouvons également les créer à partir de listes :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1],\n",
       "        [1, 1, 1],\n",
       "        [0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "x = torch.tensor([[0, 0, 1], [1, 1, 1], [0, 0, 0]])\n",
    "x"
   ]
  },
  {
   "source": [
    "On peut changer les éléments d'un tenseur en utilisant le système standard d'indexation de Python"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[5, 0, 1],\n",
       "        [1, 1, 1],\n",
       "        [0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "x[0][0] = 5\n",
    "x"
   ]
  },
  {
   "source": [
    "On peut utiliser des fonctions de création spéciales pour générer des types particuliers de tenseurs. En particulier, `ones()` et `zeros()` vont générer des tenseurs remplis de 1 et de 0, respectivement :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "torch.zeros(2, 2)"
   ]
  },
  {
   "source": [
    "On peut effectuer des opérations mathématiques standard avec des tenseurs (par exemple, additionner deux tenseurs) :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2., 2.]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "torch.ones(1, 2) + torch.ones(1, 2)"
   ]
  },
  {
   "source": [
    "Et si vous avez un tenseur de rang 0, vous pouvez en extraire la valeur avec `item()` :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.013902544975280762"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "torch.rand(1).item()"
   ]
  },
  {
   "source": [
    "Les tenseurs peuvent vivre dans le CPU ou sur le GPU et peuvent être copiés entre les dispositifs en utilisant la fonction `to()` :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "cpu_tensor = torch.rand(2)\n",
    "cpu_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "gpu_tensor = cpu_tensor.to(\"cuda\")\n",
    "gpu_tensor.device"
   ]
  },
  {
   "source": [
    "## Opérations Tensorielles"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Tout d'abord, nous avons souvent besoin de trouver l'élément maximal dans un tenseur ainsi que l'index qui contient la valeur maximale. Ceci peut être fait avec les fonctions `max()` et `argmax()`. Nous pouvons également utiliser `item()` pour extraire une valeur standard Python d'un tenseur à une dimension."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.3832)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "torch.rand(2, 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.950043261051178"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "torch.rand(2, 2).max().item()"
   ]
  },
  {
   "source": [
    "Parfois, nous souhaitons changer le type d'un tenseur, par exemple en passant d'un **LongTensor** à un **FloatTensor**. Nous pouvons le faire avec `to()` :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "long_tensor = torch.tensor([[0, 0, 1], [1, 1, 1], [0, 0, 0]])\n",
    "long_tensor.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "float_tensor = torch.tensor([[0, 0, 1], [1, 1, 1], [0, 0, 0]]).to(dtype=torch.float32)\n",
    "float_tensor.type()"
   ]
  },
  {
   "source": [
    "La plupart des fonctions qui opèrent sur un tenseur et retournent un tenseur créent un nouveau tenseur pour stocker le résultat. Toutefois, si vous voulez économiser de la mémoire, vérifiez si une fonction *in-place* est définie, elle devrait avoir le même nom que la fonction originale mais avec un underscore (_)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.3971, -0.6222],\n",
       "        [-1.7551, -0.2403]])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "random_tensor = torch.rand(2, 2)\n",
    "random_tensor.log2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.3971, -0.6222],\n",
       "        [-1.7551, -0.2403]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "random_tensor.log2_()"
   ]
  },
  {
   "source": [
    "Une autre opération courante consiste à remodeler un tenseur. Cela peut souvent se produire parce que la couche de votre réseau de neurones peut nécessiter une forme d'entrée légèrement différente de celle que vous avez actuellement à lui fournir. Par exemple, l'ensemble de données de *Modified National Institute of Standard and Technology* (MNIST) de chiffres manuscrits est une collection de $28*28$ images, mais il est présenté sous forme de tableaux de tenseurs de longueur $1*28*28$ (le 1 initial correspond au nombre de canaux - normalement rouge, vert et bleu - mais comme les chiffres MNIST sont en niveaux de gris, nous n'avons qu'un seul canal). Nous pouvons faire cela avec `view()` ou `reshape()` :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "flat_tensor = torch.rand(784)\n",
    "viewed_tensor = flat_tensor.view(1, 28, 28)\n",
    "viewed_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "reshaped_tensor = flat_tensor.reshape(1, 28, 28)\n",
    "reshaped_tensor.shape"
   ]
  },
  {
   "source": [
    "Maintenant, vous vous demandez peut-être quelle est la différence entre `view()` et `reshape()`. La réponse est que `view()` opère comme une vue sur le tenseur original, donc si les données sous-jacentes sont modifiées, la vue le sera aussi (et vice versa). Cependant, `view()` peut provoquer des erreurs si la vue requise n'est pas [contiguous](https://stackoverflow.com/questions/26998223/what-is-the-difference-between-contiguous-and-non-contiguous-arrays/26999092#26999092) ; c'est-à-dire qu'elle ne partage pas le même bloc de mémoire qu'elle occuperait si un nouveau tenseur de la forme requise était créé de toutes pièces. Si cela se produit, vous devez appeler `tensor.contiguous()` avant de pouvoir utiliser `view()`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Enfin, vous pouvez avoir besoin de réorganiser les dimensions d'un tenseur. Vous rencontrerez probablement ce problème avec les images, qui sont souvent stockées sous forme de tenseurs \\[height, width, channel\\], mais PyTorch préfère les traiter dans un \\[channel, height, width\\]. Vous pouvez utiliser `permute()` pour les traiter de manière assez simple :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 640, 480])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "hwc_tensor = torch.rand(640, 480, 3)\n",
    "chw_tensor = hwc_tensor.permute(2, 0, 1)\n",
    "chw_tensor.shape"
   ]
  },
  {
   "source": [
    "# Classification d'Images avec PyTorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Défintion du Problème"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Ici, nous construisons un classificateur simple qui peut faire la différence entre les poissons et les chats. Nous allons itérer sur la conception et la manière dont nous construisons notre modèle pour le rendre plus précis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Challenges Habituels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Premièrement, nous avons besoin de données. Combien de données ? ça dépend. L'idée selon laquelle, pour que toute technique d'apprentissage profond fonctionne, il faut de grandes quantités de données pour entraîner le réseau de neurones n'est pas nécessairement vraie. Cependant, pour l'instant, nous allons nous entraîner à partir de zéro, ce qui nécessite souvent l'accès à une grande quantité de données. Nous avons besoin de beaucoup de photos de poissons et de chats.\n",
    "\n",
    "Nous pourrions passer du temps à télécharger de nombreuses images à partir d'un moteur de recherche comme Google Image, mais dans ce cas, nous disposons d'un raccourci : une collection standard d'images utilisée pour former les réseaux neuronaux, appelée *ImageNet*. Elle contient plus de 14 millions d'images et 20 000 catégories d'images. C'est la norme à laquelle tous les classificateurs d'images se mesurent.\n",
    "\n",
    "Comme nous utilisons les données ImageNet, leurs étiquettes ne seront pas très utiles, car elles contiennent trop d'informations pour nous. Une étiquette de chat tabby ou de truite est, pour l'ordinateur, distincte de celle de chat ou de poisson. Nous devrons les réétiqueter."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## PyTorch et le Chargement de Données"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Le chargement et la conversion des données dans des formats prêts pour l'entraînement peuvent souvent finir par être l'un des domaines de la science des données qui accapare beaucoup trop de notre temps (comme pour ce foutu NER pour WaKED). PyTorch a développé des conventions standard d'interaction avec les données qui rendent le travail assez cohérent, que vous travailliez avec des images, du texte ou de l'audio.\n",
    "\n",
    "Les deux principales conventions d'interaction avec les données sont les *datasets* et les *data loaders*. Un *datasets* est une classe Python qui nous permet d'accéder aux données que nous fournissons au réseau neuronal. Un *data loaders* est ce qui alimente le réseau en données à partir du *datasets*.\n",
    "\n",
    "Examinons d'abord le *dataste*. Tout ensemble de données, qu'il comprenne des images, de l'audio, du texte, des paysages en 3D, des informations boursières, ou autre, peut interagir avec PyTorch s'il satisfait à cette classe Python abstraite :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "source": [
    "Nous devons implémenter une méthode qui renvoie la taille de notre jeu de données (`len`), et implémenter une méthode qui peut récupérer un élément de notre jeu de données dans une paire (**étiquette**, **tenseur**). Cette méthode est appelée par le *data loader* lorsqu'il introduit des données dans le réseau neuronal pour la formation. Nous devons donc écrire un corps pour `getitem` qui peut prendre l'image et la transformer en un tenseur et le retourner avec le label pour que PyTorch puisse l'utiliser."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Construire des Données d'Entraînement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Le paquet torchvision comprend une classe appelée ImageFolder qui fait à peu près tout pour nous, à condition que nos images soient dans une structure où chaque répertoire est une étiquette."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "train_data_path = \"./train/\"\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(\n",
    "    root=train_data_path, transform=transforms\n",
    ")"
   ]
  },
  {
   "source": [
    "Les GPU sont conçus pour être rapides dans l'exécution de calculs de taille standard. Mais nous avons probablement un assortiment d'images à de nombreuses résolutions. Pour augmenter nos performances de traitement, nous mettons à l'échelle chaque image entrante à la même résolution de 64*64 via la transformation `Resize(64)`. Nous convertissons ensuite les images en un tenseur, et enfin, nous normalisons le tenseur autour d'un ensemble spécifique de points de moyenne et de déviation standard.\n",
    "\n",
    "La normalisation est importante car de nombreuses multiplications se produiront lorsque l'entrée passera par les couches du réseau de neurones ; le fait de maintenir les valeurs entrantes entre 0 et 1 empêche les valeurs de devenir trop grandes pendant la phase d'entraînement (connu sous le nom de [*problème d'explosion du gradient*](https://machinelearningmastery.com/exploding-gradients-in-neural-networks/)). \n",
    "\n",
    "La moyenne et l'écart-type choisis sont ceux de l'ensemble de données ImageNet dans son ensemble. Vous pourriez les calculer spécifiquement pour ce sous-ensemble de poissons et de chats, mais ces valeurs sont suffisamment décentes. \n",
    "Si vous travailliez sur un ensemble de données complètement différent, vous devriez calculer cette moyenne et cet écart, bien que de nombreuses personnes utilisent simplement ces constantes ImageNet et rapportent des résultats acceptables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Construire des Données de Test et de Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Nous téléchargeons un ensemble de validation, qui est une série d'images de chats et de poissons qui n'apparaissent pas dans l'ensemble d'entraînemnt. À la fin de chaque cycle d'entraînemnt (également appelé *epoch*), nous comparons cet ensemble pour nous assurer que notre réseau ne fait pas d'erreur."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_path = \"./val/\"\n",
    "val_data = torchvision.datasets.ImageFolder(\n",
    "    root=val_data_path,\n",
    "    transform=transforms\n",
    ")"
   ]
  },
  {
   "source": [
    "En plus d'un ensemble de validation, nous devons également créer un ensemble de test. Celui-ci est utilisé pour tester le modèle une fois l'entraînement terminé :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"./test/\"\n",
    "test_data = torchvision.datasets.ImageFolder(\n",
    "    root=test_data_path,\n",
    "    transform=transforms\n",
    ")"
   ]
  },
  {
   "source": [
    "Nous pouvons désormais contruire notre data loader en quelques lignes :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "source": [
    "Par défaut, les chargeurs de données de PyTorch sont réglés sur un `batch_size` de 1. Vous voudrez certainement changer cela. Bien que j'ai choisi 64 ici, vous pouvez expérimenter pour voir quelle taille de minibatch vous pouvez utiliser sans épuiser la mémoire de votre GPU. Vous pouvez également expérimenter avec certains des paramètres supplémentaires de PyTorch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Création d'un réseau"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "La création d'un réseau dans PyTorch est une affaire très Pythonique. Nous héritons d'une classe appelée `torch.nn.Network` et remplissons les méthodes `__init__` et `forward` :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "\"\"\"\n",
    "class SimpleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(12288, 84)\n",
    "        self.fc2 = torch.nn.Linear(84, 50)\n",
    "        self.fc3 = torch.nn.Linear(50, 2)\n",
    "\n",
    "    def forward_(self, x):\n",
    "        x = x.view(-1, 12288)\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = torch.nn.functional.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplenet = SimpleNet()"
   ]
  },
  {
   "source": [
    "Nous effectuons toute configuration nécessaire dans `init()`, dans ce cas, nous appelons notre constructeur **superclass** et les trois couches entièrement connectées (appelées `Linear` dans PyTorch, par opposition à `Dense` dans Keras). La méthode `forward_()` décrit comment les données circulent à travers le réseau à la fois pour l'entraînement et pour faire des prédictions (inférence). Tout d'abord, nous devons convertir le tenseur 3D ($x$ et $y$ plus les informations de couleur à trois canaux - rouge, vert, bleu -) en un tenseur 1D afin qu'il puisse être introduit dans la première couche `Linear`, et nous le faisons en utilisant `view()`. A partir de là, vous pouvez voir que nous appliquons les fonctions d'activation des couches dans l'ordre, pour finalement retourner la sortie `softmax` et nous donner notre prédiction pour cette image.\n",
    "\n",
    "Les nombres dans les couches cachées sont quelque peu arbitraires, à l'exception de la sortie de la dernière couche, qui est 2, correspondant à nos deux classes. En général, vous voulez que les données de vos couches soient compressées au fur et à mesure qu'elles descendent dans la pile. Si une couche va, disons, de 50 entrées à 100 sorties, alors le réseau pourrait apprendre en passant simplement les 50 connexions à 50 des 100 sorties et considérer que son travail est terminé. En réduisant la taille de la sortie par rapport à l'entrée avec moins de ressources, ce qui signifie, espérons-le, qu'il extrait certaines caractéristiques des images qui sont importantes pour le problème que nous essayons de résoudre ; par exemple, apprendre à repérer une nageoire ou une queue.\n",
    "\n",
    "Nous avons une prédiction, et nous pouvons la comparer avec l'étiquette réelle de l'image originale pour voir si la prédiction était correcte. Mais nous avons besoin d'un moyen de permettre à PyTorch de quantifier non seulement si une prédiction est juste ou fausse, mais aussi à quel point elle est juste ou fausse. Ceci est géré par une fonction de perte (*loss function*)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Fonctions de Perte (*Loss Functions*)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "PyTorch est livré avec une collection complète qui couvre la plupart des applications que vous êtes susceptible de rencontrer, et vous pouvez bien sûr écrire vos propres applications si vous avez un domaine très personnalisé. Dans notre cas, nous allons utiliser une fonction de perte intégrée appelée `CrossEntropyLoss` qui est recommandée pour les tâches de catégorisation multiclasse comme celle que nous effectuons ici. Une autre fonction de perte que vous êtes susceptible de rencontrer est `MSELoss`, qui est la perte quadratique moyenne standard que vous pourriez utiliser lorsque vous faites une prédiction numérique.\n",
    "\n",
    "Une chose à laquelle il faut faire attention avec `CrossEntropyLoss` est qu'il incorpore également `softmax()` dans le cadre de ses opérations, ainsi notre méthode `forward_()` devient la suivante :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to SimpleNet\n",
    "\n",
    "def forward(self, x):\n",
    "    x = x.view(-1, 12288)\n",
    "    x = torch.nn.functional.relu(self.fc1(x))\n",
    "    x = torch.nn.functional.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "source": [
    "## Optimisation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Pour le problème des minima locaux, nous apportons une légère modification au fait que nous prenons tous les gradients possibles et indiquons des gradients aléatoires pendant un batch. Connue sous le nom de [*stochastic gradient descent* (SGD)](https://www.geeksforgeeks.org/ml-stochastic-gradient-descent-sgd/)~[[2]](#2), il s'agit de l'approche traditionnelle de l'optimisation des réseaux neuronaux et autres techniques d'apprentissage automatique. Mais d'autres optimiseurs sont disponibles, et en fait pour l'apprentissage profond, préférables. PyTorch est livré avec SGD et d'autres optimiseurs comme [AdaGrad](https://www.geeksforgeeks.org/intuition-behind-adagrad-optimizer/) et [RMSProp](https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a), ainsi qu'[Adam](https://www.geeksforgeeks.org/intuition-of-adam-optimizer/)~[[3]](#3).\n",
    "\n",
    "L'une des principales améliorations apportées par **Adam** (tout comme **RMSProp** et **AdaGrad**) est qu'il utilise un taux d'apprentissage par paramètre, et adapte ce taux d'apprentissage en fonction du taux de changement de ces paramètres. Il conserve une liste exponentiellement décroissante de gradients et du carré de ces gradients et les utilise pour mettre à l'échelle le taux d'apprentissage global avec lequel **Adam** travaille. Il a été démontré empiriquement que **Adam** surpasse la plupart des autres optimiseurs dans les réseaux d'apprentissage profond, mais vous pouvez remplacer Adam par **SGD** ou **RMSProp** ou un autre optimiseur pour voir si l'utilisation d'une technique différente permet un apprentissage plus rapide et plus efficace pour votre application particulière.\n",
    "\n",
    "La création d'un optimiseur basé sur **Adam** est simple. Nous appelons `torch.optim.Adam()` et passons les poids du réseau qu'il va mettre à jour (obtenus via `simmplenet.parameters()`) et notre taux d'apprentissage de 0.001 :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(simplenet.parameters(), lr=0.001)"
   ]
  },
  {
   "source": [
    "## Entraînement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        imput, target = batch\n",
    "        output = model(input)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "source": [
    "Nous prenons un batch de notre ensemble d'entraînement à chaque itération de la boucle, ce qui est géré par notre data loader. Nous les soumettons ensuite à notre modèle et calculons la perte à partir de la sortie attendue. Pour calculer les gradients, nous appelons la méthode `backward()` sur le modèle. La méthode `optimizer.step()` utilise ensuite ces gradients pour effectuer l'ajustement des poids dont nous avons parlé dans la section précédente.\n",
    "\n",
    "Mais à quoi sert cet appel `zero_grad()` ? Il s'avère que les gradients calculés s'accumulent par défaut, ce qui signifie que si nous ne mettons pas à zéro les gradients à la fin de l'itération du batch, le batch suivant devra gérer le gradient de ce batch ainsi que le sien, et le batch suivant devra gérer les deux précédents, et ainsi de suite. Cela n'est pas utile, car nous voulons examiner uniquement les gradients du batch actuel pour notre optimisation à chaque itération. Nous utilisons `zero_grad()` pour nous assurer qu'ils sont remis à zéro une fois que nous avons terminé notre boucle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Fonctionnement sur GPU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "simplenet.to(device)"
   ]
  },
  {
   "source": [
    "Ici, nous copions le modèle sur le GPU si PyTorch signale qu'un GPU est disponible, ou sinon nous gardons le modèle sur le CPU. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Mise en Commun"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=20, device=\"cpu\"):\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, target = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, accuracy = {:.2f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(simplenet, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, val_data_loader, epochs=5, device=device)"
   ]
  },
  {
   "source": [
    "## Prédictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Voici un petit bout de code Python qui chargera une image depuis le système de fichiers et dira si notre réseau prédit un chat ou poisson."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "labels = [\"chat\",\"poisson\"]\n",
    "\n",
    "img = Image.open(\"./val/fish/100_1422.JPG\") \n",
    "img = img_transforms(img).to(device)\n",
    "img = torch.unsqueeze(img, 0)\n",
    "\n",
    "simplenet.eval()\n",
    "prediction = F.softmax(simplenet(img), dim=1)\n",
    "prediction = prediction.argmax()\n",
    "print(labels[prediction])"
   ]
  },
  {
   "source": [
    "Comme notre réseau utilise des lots, il s'attend en fait à un tenseur 4D, la première dimension représentant les différentes images d'un lot. Nous n'avons pas de lot, mais nous pouvons créer un lot de longueur 1 en utilisant `unsqueeze(0)`, qui ajoute une nouvelle dimension à l'avant de notre tenseur."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Sauvegarder le Modèle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Si vous êtes satisfait des performances d'un modèle ou si vous avez besoin de vous arrêter, vous pouvez sauvegarder l'état actuel d'un modèle au format *pickle* de Python en utilisant la méthode `torch.save()`. Inversement, vous pouvez charger une interation précédemment sauvegardée d'un modèle en utilisant la méthode `torch.load()`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(simplenet, \"/tmp/simplenet\") \n",
    "simplenet = torch.load(\"/tmp/simplenet\")"
   ]
  },
  {
   "source": [
    "Cela permet de stocker les paramètres et la structure du modèle dans un fichier. Cela peut poser un problème si vous modifiez la structure du modèle ultérieurement. Pour cette raison, il est plus courant de sauvegarder le `state_dict` d'un modèle à la place. C'est un `dict` Python standard qui contient les cartes pour les paramètres de chaque couche du modèle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(simplenet.state_dict(), \"/tmp/simplenet\")    \n",
    "simplenet = SimpleNet()\n",
    "simplenet_state_dict = torch.load(\"/tmp/simplenet\")\n",
    "simplenet.load_state_dict(simplenet_state_dict)"
   ]
  },
  {
   "source": [
    "# Réseaux Neuronaux Convolutifs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Avec des réseaux entièrement connectés, si vous essayez d'ajouter des couches supplémentaires ou d'augmenter considérablement le nombre de paramètres, vous allez certainement manquer de mémoire sur votre GPU. De plus, l'entraînement jusqu'à une précision décente prendrait un certain temps.\n",
    "\n",
    "Il est vrai qu'un réseau entièrement connecté ou (*feed-forward*) peut fonctionner comme un approximateur universel, mais la théorie ne dit pas combien de temps il vous faudra pour l'entraîner à devenir cette approximation de la fonction que vous recherchez vraiment. Mais on peut faire mieux, surtout avec les images."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Premier Modèle Convolutif"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "source": [
    "La première chose à remarquer est l'utilisation de `nn.Sequential()`. Cela nous permet de créer une chaîne de couches (*layers*). Lorsque nous utilisons une de ces chaînes dans `forward()`, l'entrée passe par chacune des couches en succession. Vous pouvez utiliser ceci pour décomposer votre modèle en arrangements plus logiques. Dans ce réseau, nous avons deux chaînes : le bloc `features` et le `classifier`. Jetons un coup d'oeil aux nouvelles couches que nous introduisons, en commençant par `Conv2d`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convolutions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "La couche `Conv2d` est une convolution 2D. Si nous avons une image en niveaux de gris, elle consiste en un tableau de $x$ pixels de large et $y$ pixels de haut, dont chaque entrée a une valeur qui indique si elle est noire ou blanche ou quelque part entre les deux (nous supposons une image de 8 bits, donc chaque valeur peut varier de 0 à 255).\n",
    "\n",
    "![](https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_02_17A-ConvolutionalNeuralNetworks-WHITEBG.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# References"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<a id=\"1\">[1]</a> \n",
    "Rajat Raina et al. (2009). \n",
    "\"Large-Scale Deep Unsupervised Learning Using Graphics Processors\". \n",
    "*Proceedings of the 26th Annual International Conference on Machine Learning*, 873–880.\n",
    "https://doi.org/10.1145/1553374.1553486\n",
    "\n",
    "<a id=\"2\">[2]</a> \n",
    "Sebastian Ruder (2016). \n",
    "\"An overview of gradient descent optimization algorithms\". \n",
    "*CoRR*, abs/1609.04747.\n",
    "https://arxiv.org/abs/1609.04747\n",
    "\n",
    "<a id=\"3\">[3]</a> \n",
    "Diederik P.Kingama, Jimmy Ba (2014). \n",
    "\"Adam: A Method for Stochastic Optimization\". \n",
    "*3rd International Conference on Learning Representations, ICLR 2015*.\n",
    "https://arxiv.org/abs/1412.6980"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}