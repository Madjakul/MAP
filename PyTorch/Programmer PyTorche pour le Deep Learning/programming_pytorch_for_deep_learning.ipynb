{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "venv_mappytorch",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Les réseaux de neurones convolutifs ont été utilisés pour reconnaître les chiffres des chèques à la fin des années 90. Il y a eu une base solide pendant tout ce temps, alors pourquoi a-t-on l'impression qu'une explosion s'est produite au cours des dix dernières années ?\n",
    "\n",
    "Les raisons sont nombreuses, mais la principale d'entre elles est l'augmentation des performances des GPU et leur prix de plus en plus abordable. Conçus à l'origine pour les jeux, les GPU doivent effectuer des millions d'opérations matricielles par seconde afin de restituer tous les polygones du jeu de conduite ou de tir auquel vous jouez sur votre console ou votre PC, opérations pour lesquelles un CPU standard n'est tout simplement pas optimisé.\n",
    "\n",
    "Un article publié en 2009~[[1]](#1) soulignait que la formation des réseaux de neurones reposait également sur l'exécution d'un grand nombre d'opérations matricielles. Ces cartes graphiques supplémentaires pourraient donc être utilisées pour accélérer la formation et rendre possible, pour la première fois des architectures de réseaux neuronaux plus grandes et plus profondes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Démarrer avec PyTorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "!nvidia-smi"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Thu Jul  1 19:39:37 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:2D:00.0  On |                  N/A |\n",
      "|  0%   43C    P5    39W / 215W |   1065MiB /  7981MiB |     35%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1644      G   /usr/lib/xorg/Xorg                102MiB |\n",
      "|    0   N/A  N/A      2598      G   /usr/lib/xorg/Xorg                413MiB |\n",
      "|    0   N/A  N/A      2758      G   /usr/bin/gnome-shell               82MiB |\n",
      "|    0   N/A  N/A      3407      G   ...AAAAAAAAA= --shared-files       22MiB |\n",
      "|    0   N/A  N/A      3853      G   /usr/lib/firefox/firefox          161MiB |\n",
      "|    0   N/A  N/A      3936      G   ...gAAAAAAAAA --shared-files      159MiB |\n",
      "|    0   N/A  N/A      4163      G   ...AAAAAAAAA= --shared-files       19MiB |\n",
      "|    0   N/A  N/A     29850      G   ...AAAAAAAAA= --shared-files       66MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "source": [
    "CUDA Version 11.3, on peut donc procéder à l'installation de PyTorch via les instructions trouvable sur leur [site web](https://pytorch.org/)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.9.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (2041.3 MB)\n",
      "Collecting torchvision==0.10.0+cu111\n",
      "  Using cached https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp38-cp38-linux_x86_64.whl (23.2 MB)\n",
      "Collecting torchaudio==0.9.0\n",
      "  Using cached torchaudio-0.9.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: typing-extensions in /home/madjakul/.local/lib/python3.8/site-packages (from torch==1.9.0+cu111) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision==0.10.0+cu111) (7.0.0)\n",
      "Requirement already satisfied: numpy in /home/madjakul/.local/lib/python3.8/site-packages (from torchvision==0.10.0+cu111) (1.19.5)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.8.1\n",
      "    Uninstalling torch-1.8.1:\n",
      "      Successfully uninstalled torch-1.8.1\n",
      "Successfully installed torch-1.9.0+cu111 torchaudio-0.9.0 torchvision-0.10.0+cu111\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "source": [
    "On s'assure ici que CUDA est accesible et crée un tenseur à valeurs aléatoires de taille 2*2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\ntensor([[0.0013, 0.9979],\n        [0.3422, 0.2302]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.rand(2, 2))"
   ]
  },
  {
   "source": [
    "## Tenseurs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Un tenseur est à la fois un conteneur pour les nombres et un ensemble de tuples qui définissent les transformations entre les tenseurs qui produisent de nouveaux tenseurs.\n",
    "\n",
    "Chaque tenseur a un rang qui correspond à son espace dimensionnel. Un simple scalaire—par exemple, 1—peut être représenté comme un tenseur de rang 0, un vecteur est de rang 1, une matrice $n*n$ est de rang 2, et ainsi de suite. Dans l'exemple précédent, nous avons créé un tenseur de rang 2 avec des valeurs aléatoires en utilisant `torch.rand()`. Nous pouvons également les créer à partir de listes :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1],\n",
       "        [1, 1, 1],\n",
       "        [0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "x = torch.tensor([[0, 0, 1], [1, 1, 1], [0, 0, 0]])\n",
    "x"
   ]
  },
  {
   "source": [
    "On peut changer les éléments d'un tenseur en utilisant le système standard d'indexation de Python"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[5, 0, 1],\n",
       "        [1, 1, 1],\n",
       "        [0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "x[0][0] = 5\n",
    "x"
   ]
  },
  {
   "source": [
    "On peut utiliser des fonctions de création spéciales pour générer des types particuliers de tenseurs. En particulier, `ones()` et `zeros()` vont générer des tenseurs remplis de 1 et de 0, respectivement :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "torch.zeros(2, 2)"
   ]
  },
  {
   "source": [
    "On peut effectuer des opérations mathématiques standard avec des tenseurs (par exemple, additionner deux tenseurs) :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[2., 2.]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "torch.ones(1, 2) + torch.ones(1, 2)"
   ]
  },
  {
   "source": [
    "Et si vous avez un tenseur de rang 0, vous pouvez en extraire la valeur avec `item()` :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.013902544975280762"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "torch.rand(1).item()"
   ]
  },
  {
   "source": [
    "Les tenseurs peuvent vivre dans le CPU ou sur le GPU et peuvent être copiés entre les dispositifs en utilisant la fonction `to()` :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "cpu_tensor = torch.rand(2)\n",
    "cpu_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "gpu_tensor = cpu_tensor.to(\"cuda\")\n",
    "gpu_tensor.device"
   ]
  },
  {
   "source": [
    "## Opérations Tensorielles"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Tout d'abord, nous avons souvent besoin de trouver l'élément maximal dans un tenseur ainsi que l'index qui contient la valeur maximale. Ceci peut être fait avec les fonctions `max()` et `argmax()`. Nous pouvons également utiliser `item()` pour extraire une valeur standard Python d'un tenseur à une dimension."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.3832)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "torch.rand(2, 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.950043261051178"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "torch.rand(2, 2).max().item()"
   ]
  },
  {
   "source": [
    "Parfois, nous souhaitons changer le type d'un tenseur, par exemple en passant d'un **LongTensor** à un **FloatTensor**. Nous pouvons le faire avec `to()` :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'torch.LongTensor'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "long_tensor = torch.tensor([[0, 0, 1], [1, 1, 1], [0, 0, 0]])\n",
    "long_tensor.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "float_tensor = torch.tensor([[0, 0, 1], [1, 1, 1], [0, 0, 0]]).to(dtype=torch.float32)\n",
    "float_tensor.type()"
   ]
  },
  {
   "source": [
    "La plupart des fonctions qui opèrent sur un tenseur et retournent un tenseur créent un nouveau tenseur pour stocker le résultat. Toutefois, si vous voulez économiser de la mémoire, vérifiez si une fonction *in-place* est définie, elle devrait avoir le même nom que la fonction originale mais avec un underscore (_)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.3971, -0.6222],\n",
       "        [-1.7551, -0.2403]])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "random_tensor = torch.rand(2, 2)\n",
    "random_tensor.log2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[-2.3971, -0.6222],\n",
       "        [-1.7551, -0.2403]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "random_tensor.log2_()"
   ]
  },
  {
   "source": [
    "Une autre opération courante consiste à remodeler un tenseur. Cela peut souvent se produire parce que la couche de votre réseau de neurones peut nécessiter une forme d'entrée légèrement différente de celle que vous avez actuellement à lui fournir. Par exemple, l'ensemble de données de *Modified National Institute of Standard and Technology* (MNIST) de chiffres manuscrits est une collection de $28*28$ images, mais il est présenté sous forme de tableaux de tenseurs de longueur $1*28*28$ (le 1 initial correspond au nombre de canaux - normalement rouge, vert et bleu - mais comme les chiffres MNIST sont en niveaux de gris, nous n'avons qu'un seul canal). Nous pouvons faire cela avec `view()` ou `reshape()` :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "flat_tensor = torch.rand(784)\n",
    "viewed_tensor = flat_tensor.view(1, 28, 28)\n",
    "viewed_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "reshaped_tensor = flat_tensor.reshape(1, 28, 28)\n",
    "reshaped_tensor.shape"
   ]
  },
  {
   "source": [
    "Maintenant, vous vous demandez peut-être quelle est la différence entre `view()` et `reshape()`. La réponse est que `view()` opère comme une vue sur le tenseur original, donc si les données sous-jacentes sont modifiées, la vue le sera aussi (et vice versa). Cependant, `view()` peut provoquer des erreurs si la vue requise n'est pas [contiguous](https://stackoverflow.com/questions/26998223/what-is-the-difference-between-contiguous-and-non-contiguous-arrays/26999092#26999092) ; c'est-à-dire qu'elle ne partage pas le même bloc de mémoire qu'elle occuperait si un nouveau tenseur de la forme requise était créé de toutes pièces. Si cela se produit, vous devez appeler `tensor.contiguous()` avant de pouvoir utiliser `view()`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Enfin, vous pouvez avoir besoin de réorganiser les dimensions d'un tenseur. Vous rencontrerez probablement ce problème avec les images, qui sont souvent stockées sous forme de tenseurs \\[height, width, channel\\], mais PyTorch préfère les traiter dans un \\[channel, height, width\\]. Vous pouvez utiliser `permute()` pour les traiter de manière assez simple :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 640, 480])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "hwc_tensor = torch.rand(640, 480, 3)\n",
    "chw_tensor = hwc_tensor.permute(2, 0, 1)\n",
    "chw_tensor.shape"
   ]
  },
  {
   "source": [
    "# Classification d'Images avec PyTorch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Défintion du Problème"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Ici, nous construisons un classificateur simple qui peut faire la différence entre les poissons et les chats. Nous allons itérer sur la conception et la manière dont nous construisons notre modèle pour le rendre plus précis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Challenges Habituels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Premièrement, nous avons besoin de données. Combien de données ? ça dépend. L'idée selon laquelle, pour que toute technique d'apprentissage profond fonctionne, il faut de grandes quantités de données pour entraîner le réseau de neurones n'est pas nécessairement vraie. Cependant, pour l'instant, nous allons nous entraîner à partir de zéro, ce qui nécessite souvent l'accès à une grande quantité de données. Nous avons besoin de beaucoup de photos de poissons et de chats.\n",
    "\n",
    "Nous pourrions passer du temps à télécharger de nombreuses images à partir d'un moteur de recherche comme Google Image, mais dans ce cas, nous disposons d'un raccourci : une collection standard d'images utilisée pour former les réseaux neuronaux, appelée *ImageNet*. Elle contient plus de 14 millions d'images et 20 000 catégories d'images. C'est la norme à laquelle tous les classificateurs d'images se mesurent.\n",
    "\n",
    "Comme nous utilisons les données ImageNet, leurs étiquettes ne seront pas très utiles, car elles contiennent trop d'informations pour nous. Une étiquette de chat tabby ou de truite est, pour l'ordinateur, distincte de celle de chat ou de poisson. Nous devrons les réétiqueter."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## PyTorch et le Chargement de Données"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Le chargement et la conversion des données dans des formats prêts pour l'entraînement peuvent souvent finir par être l'un des domaines de la science des données qui accapare beaucoup trop de notre temps (comme pour ce foutu NER pour WaKED). PyTorch a développé des conventions standard d'interaction avec les données qui rendent le travail assez cohérent, que vous travailliez avec des images, du texte ou de l'audio.\n",
    "\n",
    "Les deux principales conventions d'interaction avec les données sont les *datasets* et les *data loaders*. Un *datasets* est une classe Python qui nous permet d'accéder aux données que nous fournissons au réseau neuronal. Un *data loaders* est ce qui alimente le réseau en données à partir du *datasets*.\n",
    "\n",
    "Examinons d'abord le *dataste*. Tout ensemble de données, qu'il comprenne des images, de l'audio, du texte, des paysages en 3D, des informations boursières, ou autre, peut interagir avec PyTorch s'il satisfait à cette classe Python abstraite :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "source": [
    "Nous devons implémenter une méthode qui renvoie la taille de notre jeu de données (`len`), et implémenter une méthode qui peut récupérer un élément de notre jeu de données dans une paire (**étiquette**, **tenseur**). Cette méthode est appelée par le *data loader* lorsqu'il introduit des données dans le réseau neuronal pour la formation. Nous devons donc écrire un corps pour `getitem` qui peut prendre l'image et la transformer en un tenseur et le retourner avec le label pour que PyTorch puisse l'utiliser."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Construire des Données d'Entraînement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Le paquet torchvision comprend une classe appelée ImageFolder qui fait à peu près tout pour nous, à condition que nos images soient dans une structure où chaque répertoire est une étiquette."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "train_data_path = \"./train/\"\n",
    "\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(\n",
    "    root=train_data_path, transform=transforms\n",
    ")"
   ]
  },
  {
   "source": [
    "Les GPU sont conçus pour être rapides dans l'exécution de calculs de taille standard. Mais nous avons probablement un assortiment d'images à de nombreuses résolutions. Pour augmenter nos performances de traitement, nous mettons à l'échelle chaque image entrante à la même résolution de 64*64 via la transformation `Resize(64)`. Nous convertissons ensuite les images en un tenseur, et enfin, nous normalisons le tenseur autour d'un ensemble spécifique de points de moyenne et de déviation standard.\n",
    "\n",
    "La normalisation est importante car de nombreuses multiplications se produiront lorsque l'entrée passera par les couches du réseau de neurones ; le fait de maintenir les valeurs entrantes entre 0 et 1 empêche les valeurs de devenir trop grandes pendant la phase d'entraînement (connu sous le nom de [*problème d'explosion du gradient*](https://machinelearningmastery.com/exploding-gradients-in-neural-networks/)). \n",
    "\n",
    "La moyenne et l'écart-type choisis sont ceux de l'ensemble de données ImageNet dans son ensemble. Vous pourriez les calculer spécifiquement pour ce sous-ensemble de poissons et de chats, mais ces valeurs sont suffisamment décentes. \n",
    "Si vous travailliez sur un ensemble de données complètement différent, vous devriez calculer cette moyenne et cet écart, bien que de nombreuses personnes utilisent simplement ces constantes ImageNet et rapportent des résultats acceptables."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Construire des Données de Test et de Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Nous téléchargeons un ensemble de validation, qui est une série d'images de chats et de poissons qui n'apparaissent pas dans l'ensemble d'entraînemnt. À la fin de chaque cycle d'entraînemnt (également appelé *epoch*), nous comparons cet ensemble pour nous assurer que notre réseau ne fait pas d'erreur."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_path = \"./val/\"\n",
    "val_data = torchvision.datasets.ImageFolder(\n",
    "    root=val_data_path,\n",
    "    transform=transforms\n",
    ")"
   ]
  },
  {
   "source": [
    "En plus d'un ensemble de validation, nous devons également créer un ensemble de test. Celui-ci est utilisé pour tester le modèle une fois l'entraînement terminé :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = \"./test/\"\n",
    "test_data = torchvision.datasets.ImageFolder(\n",
    "    root=test_data_path,\n",
    "    transform=transforms\n",
    ")"
   ]
  },
  {
   "source": [
    "Nous pouvons désormais contruire notre data loader en quelques lignes :"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "source": [
    "Par défaut, les chargeurs de données de PyTorch sont réglés sur un `batch_size` de 1. Vous voudrez certainement changer cela. Bien que j'ai choisi 64 ici, vous pouvez expérimenter pour voir quelle taille de minibatch vous pouvez utiliser sans épuiser la mémoire de votre GPU. Vous pouvez également expérimenter avec certains des paramètres supplémentaires de PyTorch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# References"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<a id=\"1\">[1]</a> \n",
    "Rajat RAINA et al.(2009). \n",
    "\"Large-Scale Deep Unsupervised Learning Using Graphics Processors\". \n",
    "*_Proceedings of the 26th Annual International Conference on Machine Learning_*, 8, 873–880.\n",
    "https://doi.org/10.1145/1553374.1553486"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}